{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge project Ideas.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZefAAwAflmF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Challenge Project v.2**\n",
        "\n",
        "---\n",
        "\n",
        "This version allows for much more freedom, but more grading .. with only 22-23 students, I'm fine with that\n",
        "the success of this version will be determined by how active, excited, comfortable the students are (will help prepare for week 4, too!!) (Thanks Mr. Rod for the inspiration)\n",
        "\n",
        "* not only helps build and enforce their knowledge of the curriculum, but also public speaking skills, appropriate statistical proceduring and considerations, etc. \n",
        "\n",
        "* Idea founded in the expression: \"we remember 10% of what we read, 20% of what we hear, 30% of what we see, 50% of what we see and hear, 70% of what we discuss with others, 80% of what we personally experience\n",
        "95% or what we teach others\". So why not just teach?\n",
        "\n",
        "* group or individual... or assigned group?\n",
        "\n",
        "* students can only use algorithms learned so far (classification)\n",
        "\n",
        "* may need to increase allotted time for group presentations (currently is 1 hour, 1 hour extra is probably enough) \n",
        "\n",
        "* take proposals from students first? or just assign research questions to each of the datasets?\n",
        "\n",
        "The students will be tasked with taking a dataset and performing a full-on analysis procedure of the data, from the data cleaning to model evaluation. By giving the students an extensive, on-hands project, the aim is to reinforce their knowledge of the course curriculum, test their ability to accurately perform a typical analysis procedure, improve their communication and public speaking skills, and gain valuable insights into what is expected of them in this field.\n",
        "\n",
        "Rough guideline of project:\n",
        "\n",
        ">1.   Acquire/choose data\n",
        "2.   Clean data as necessary\n",
        "3.   further data visualization, analysis\n",
        "4.   Select best model\n",
        ">>4. Compare with other models\n",
        "5.   Evaluate model\n",
        ">>5. Sensitivity, specificity?\n",
        "6.   Conclusion (any insights you can make?)\n",
        "7.   Presentation?? (8-12 minutes)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Sf2Y3rU52gz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hypothesis Testing\n",
        "\n",
        "H.P.F.P.D.C.\n",
        "\n",
        ">**H**   Hypothesis. State null, alternate hypotheses. In case of classification model selection, the alternate would be the performance of the model you selected, the null would be the other models. Could probably just run a chi-squared GOF test if metric is a proportion.\n",
        "\n",
        ">>in case of a specific model, the alternate would be the model you are using, and the null would be 0 or the proportion if one were to guess \"no\" for all or \"yes\" (depending on which value is higher) (in the case of AUROC, null would be 0.5)\n",
        "\n",
        ">**P** Preconditions. Data is unbiased (therefore the true center isn't), large sample (n>30), records are independent (therefore variance in data is not skewed)\n",
        "\n",
        ">**F** Formula. Depends on how you are comparing values (Chi-squared? 1-Prop z-test?)\n",
        "\n",
        ">**P** Probability/P-value. The probability of receiving these results assuming the null hypothesis was true. If the p-value was low, that means that if the null hypothesis was true, then a miracle just happened, so it's better to say instead that the null hypothesis was \"false.\"\n",
        "\n",
        ">**D** Decision. Do you reject/fail to reject null?\n",
        "\n",
        ">**C** Conclusion. Is there enough evidence to suggest that the models are similar in performance/better/worse?\n",
        "\n",
        "\n",
        "Why is hypothesis testing important? Well, let's do a quick demonstration: Show of hands, who thinks 50/100 is different enough from 50/100 so that it matters? 51? 52? 53?...60? As you can see, not everyone agreed on when two numbers were considered \"different enough.\" Hypothesis testing, statistics in general, really, objectively quantifies this discrepancy and therefore eliminates it. It allows for coherent structuring of a question, procedure, and answer universally understandable. That said, there is a difference between \"clinical\" significance and \"statistical\" significance. But that's problem for another day."
      ]
    },
    {
      "metadata": {
        "id": "ijcN7j5Y4WbL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "###C.P. v2 Example\n",
        "\n",
        "###################################################Acquire data (1)###################################################\n",
        "!pip install -q xlrd\n",
        "%cd bwsi_testsets\n",
        "!git clone https://github.com/lylemp/bwsi_testsets.git #with public datasets just replace URL\n",
        "!ls bwsi_testsets #shows the files in this folder. pick the dataset you want\n",
        "import pandas as po\n",
        "dataset=po.read_csv('bwsi_testsets/diabetes.csv')\n",
        "\n",
        "\n",
        "###################################################cleaning data, data preanalysis (2)###################################################\n",
        "dataset.isnull().sum()\n",
        "dataset['Outcome']=dataset['Outcome'].astype('int64')\n",
        "dataset[dataset.columns!=\"?\"]\n",
        "\n",
        "dataset.info()\n",
        "\n",
        "dataset.describe()\n",
        "\n",
        "###################################################data visualization (3)###################################################\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as py\n",
        "dataset.corr()\n",
        "sns.heatmap(dataset.corr(),annot=True,cbar=True) #if seaborn is allowed\n",
        "py.matshow(dataset.corr())\n",
        "sns.pairplot(dataset)\n",
        "#etc.\n",
        "\n",
        "###################################################model selection (4)###################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "outcome=dataset['Outcome']\n",
        "data=dataset[dataset.columns[:8]]\n",
        "train,test=train_test_split(dataset,test_size=0.25,random_state=0,stratify=dataset['Outcome'])# outcome stratification (>explain why)\n",
        "\n",
        "train_X=train[train.columns[:8]]\n",
        "test_X=test[test.columns[:8]]\n",
        "train_Y=train['Outcome']\n",
        "test_Y=test['Outcome']\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "types=['rbf','linear']\n",
        "for i in types:\n",
        "    svm_model=svm.SVC(kernel=i)\n",
        "    svm_model.fit(train_X,train_Y)\n",
        "    svm_prediction=svm_model.predict(test_X)\n",
        "    svm_acc=metrics.accuracy_score(svm_prediction,test_Y)\n",
        "    print('Accuracy for SVM kernel=',i,'is',svm_acc)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "a_index=list(range(1,11))\n",
        "a=pd.Series()\n",
        "x=[0,1,2,3,4,5,6,7,8,9,10]\n",
        "for i in list(range(1,11)):\n",
        "    kn_model=KNeighborsClassifier(n_neighbors=i) \n",
        "    kn_model.fit(train_X,train_Y)\n",
        "    kn_prediction=kn_model.predict(test_X)\n",
        "    a=a.append(pd.Series(metrics.accuracy_score(kn_prediction,test_Y)))\n",
        "plt.plot(a_index, a)\n",
        "plt.xticks(x)\n",
        "plt.show()\n",
        "print('Accuracies for different values of n are:',a.values)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model=DecisionTreeClassifier()\n",
        "dt_model.fit(train_X,train_Y)\n",
        "lr_prediction=dt_model.predict(test_X)\n",
        "dt_acc=metrics.accuracy_score(lr_prediction,test_Y)\n",
        "print('The accuracy of the Decision Tree is',dt_acc)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(train_X,train_Y)\n",
        "lr_prediction=lr_model.predict(test_X)\n",
        "lr_acc=metrics.accuracy_score(lr_prediction,test_Y)\n",
        "print('The accuracy of the Logistic Regression is',lr_acc)\n",
        "\n",
        "#maybe introduce K-fold cross-validation?\n",
        "\n",
        "\n",
        "###################################################model evaluation (5)###################################################\n",
        "from scipy.stats import norm\n",
        "def twopropztest(prop1,n1,prop2,n2,sign):\n",
        "  if(sign=='>'):\n",
        "    z=(prop1-prop2-0)/((prop1*(1-prop1)/n1)+(prop2*(1-prop2)/n2))**(1/2) \n",
        "    print(z)\n",
        "    return 1-norm.cdf(z,0,1)\n",
        "  \n",
        "!pip install -q xlrd\n",
        "!git clone https://github.com/lylemp/bwsi_testsets.git #with public datasets just replace URL\n",
        "!ls bwsi_testsets #shows the files in this folder. pick the dataset you want\n",
        "import pandas as po\n",
        "dataset=po.read_csv('bwsi_testsets/diabetes.csv')\n",
        "\n",
        "twopropztest(lr_acc,len(dataset),dt_acc,len(dataset),'>')\n",
        "\n",
        "\n",
        "expected=len(dataset[dataset.Outcome==1])/len(dataset)\n",
        "\n",
        "###################################################Conclusion (6)###################################################\n",
        "#there is significant evidence to suggest that the logistic regression model performs the best with an accuracy of 76% at the 5% alpha level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QdMakI9IljjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Things to consider for your conclusion:\n",
        "\n",
        "* Compare the hypothesis to the results; do the data support or reject the hypothesis? \n",
        "* What could you revise in the methods to improve the experiment? \n",
        "* What might cause the relationship between the dependent variable and the independent variables (confounding variables, outliers)? What other variables can you think of measuring to improve your model?\n",
        "* What questions were raised; are there more scientific tests that could be performed?\n",
        "* If any statistical tests were performed, be sure to include a discussion about them."
      ]
    },
    {
      "metadata": {
        "id": "XUgP5oIeHI25",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9efe3b89-eb86-490d-df70-2ea50f470346",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529689054441,
          "user_tz": 420,
          "elapsed": 293,
          "user": {
            "displayName": "Lyle Lalunio",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111684296322842137827"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "outcome=dataset['Outcome']\n",
        "data=dataset[dataset.columns[:8]]\n",
        "train,test=train_test_split(dataset,test_size=0.25,random_state=0,stratify=dataset['Outcome'])# outcome stratification (>explain why)\n",
        "\n",
        "train_X=train[train.columns[:8]]\n",
        "test_X=test[test.columns[:8]]\n",
        "train_Y=train['Outcome']\n",
        "test_Y=test['Outcome']\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model=DecisionTreeClassifier()\n",
        "dt_model.fit(train_X,train_Y)\n",
        "dt_prediction=dt_model.predict(test_X)\n",
        "dt_acc=metrics.accuracy_score(dt_prediction,test_Y)\n",
        "print('The accuracy of the Decision Tree is',dt_acc)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(train_X,train_Y)\n",
        "dt_prediction=lr_model.predict(test_X)\n",
        "lr_acc=metrics.accuracy_score(dt_prediction,test_Y)\n",
        "print('The accuracy of the Logistic Regression is',lr_acc)\n",
        "\n",
        "#maybe introduce K-fold cross-validation? (might as well if going this in-depth)\n",
        "\n",
        "from scipy.stats import norm\n",
        "def twopropztest(prop1,n1,prop2,n2,sign):\n",
        "  if(sign=='>'):\n",
        "    z=(prop1-prop2-0)/((prop1*(1-prop1)/n1)+(prop2*(1-prop2)/n2))**(1/2) \n",
        "    print('%.3f'%(z))\n",
        "    return ('%.3f' % (1-norm.cdf(z,0,1)))\n",
        "  \n",
        "twopropztest(lr_acc,len(dataset),dt_acc,len(dataset),'>')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Decision Tree is 0.7604166666666666\n",
            "The accuracy of the Logistic Regression is 0.7760416666666666\n",
            "0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.234'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "hkuZ3OOCku9I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39cb43a8-b204-4609-b9f7-3bcd96ae7064",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529689112640,
          "user_tz": 420,
          "elapsed": 278,
          "user": {
            "displayName": "Lyle Lalunio",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111684296322842137827"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "expected=len(dataset[dataset.Outcome==1])/len(dataset)\n",
        "expected2=len(dataset[dataset.Outcome==0])/len(dataset)\n",
        "expected\n",
        "expected2"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510416666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "hyni3S8Qn37V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Challenge Project v.3\n",
        "\n",
        "---\n",
        "\n",
        "Have student predict a certain outcome by creating surveys to generate data and building a model/selecting a model that gives the highest accuracy.\n",
        "\n",
        "\"I liken predicting to fortune-telling. How amazing it would be to have a machine that can tell you the results of events that haven't happened yet?\"\n"
      ]
    },
    {
      "metadata": {
        "id": "I82W-rejAEG1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1957
        },
        "outputId": "ad0b3fdc-04fe-450f-a16c-2fc90668216d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529688310679,
          "user_tz": 420,
          "elapsed": 1056,
          "user": {
            "displayName": "Lyle Lalunio",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111684296322842137827"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#cleaning data, data preanalysis (2)\n",
        "\n",
        "dataset.isnull().sum()\n",
        "dataset['Outcome']=dataset['Outcome'].astype('int64')\n",
        "for i in range(1,len(dataset)):\n",
        "  for j in range(1,len(dataset.columns)):\n",
        "    if(dataset.iloc[i,j]==0):\n",
        "      dataset.drop(dataset.index[i])\n",
        "      continue\n",
        "dataset      "
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.191</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.537</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>139</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>1.441</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>189</td>\n",
              "      <td>60</td>\n",
              "      <td>23</td>\n",
              "      <td>846</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.398</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>166</td>\n",
              "      <td>72</td>\n",
              "      <td>19</td>\n",
              "      <td>175</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0.587</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.484</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>84</td>\n",
              "      <td>47</td>\n",
              "      <td>230</td>\n",
              "      <td>45.8</td>\n",
              "      <td>0.551</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7</td>\n",
              "      <td>107</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.254</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>103</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>83</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.183</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>96</td>\n",
              "      <td>34.6</td>\n",
              "      <td>0.529</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3</td>\n",
              "      <td>126</td>\n",
              "      <td>88</td>\n",
              "      <td>41</td>\n",
              "      <td>235</td>\n",
              "      <td>39.3</td>\n",
              "      <td>0.704</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.4</td>\n",
              "      <td>0.388</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7</td>\n",
              "      <td>196</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.8</td>\n",
              "      <td>0.451</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9</td>\n",
              "      <td>119</td>\n",
              "      <td>80</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.263</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11</td>\n",
              "      <td>143</td>\n",
              "      <td>94</td>\n",
              "      <td>33</td>\n",
              "      <td>146</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0.254</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>10</td>\n",
              "      <td>125</td>\n",
              "      <td>70</td>\n",
              "      <td>26</td>\n",
              "      <td>115</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.205</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7</td>\n",
              "      <td>147</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.257</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>97</td>\n",
              "      <td>66</td>\n",
              "      <td>15</td>\n",
              "      <td>140</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0.487</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>13</td>\n",
              "      <td>145</td>\n",
              "      <td>82</td>\n",
              "      <td>19</td>\n",
              "      <td>110</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.1</td>\n",
              "      <td>0.337</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>160</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0.453</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0.293</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>11</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>37</td>\n",
              "      <td>150</td>\n",
              "      <td>42.3</td>\n",
              "      <td>0.785</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>3</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>94</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.400</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "      <td>58</td>\n",
              "      <td>18</td>\n",
              "      <td>116</td>\n",
              "      <td>28.5</td>\n",
              "      <td>0.219</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>9</td>\n",
              "      <td>140</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>0.734</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>13</td>\n",
              "      <td>153</td>\n",
              "      <td>88</td>\n",
              "      <td>37</td>\n",
              "      <td>140</td>\n",
              "      <td>40.6</td>\n",
              "      <td>1.174</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>84</td>\n",
              "      <td>33</td>\n",
              "      <td>105</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.488</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>1</td>\n",
              "      <td>147</td>\n",
              "      <td>94</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>49.3</td>\n",
              "      <td>0.358</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>46.3</td>\n",
              "      <td>1.096</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>3</td>\n",
              "      <td>187</td>\n",
              "      <td>70</td>\n",
              "      <td>22</td>\n",
              "      <td>200</td>\n",
              "      <td>36.4</td>\n",
              "      <td>0.408</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.178</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>4</td>\n",
              "      <td>136</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>1.182</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>78</td>\n",
              "      <td>39</td>\n",
              "      <td>74</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.261</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>3</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.223</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>0</td>\n",
              "      <td>181</td>\n",
              "      <td>88</td>\n",
              "      <td>44</td>\n",
              "      <td>510</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.222</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>8</td>\n",
              "      <td>154</td>\n",
              "      <td>78</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>32.4</td>\n",
              "      <td>0.443</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>110</td>\n",
              "      <td>36.5</td>\n",
              "      <td>1.057</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>7</td>\n",
              "      <td>137</td>\n",
              "      <td>90</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.391</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0.258</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>0.197</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.278</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>2</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.766</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>9</td>\n",
              "      <td>170</td>\n",
              "      <td>74</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.403</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.142</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "5              5      116             74              0        0  25.6   \n",
              "6              3       78             50             32       88  31.0   \n",
              "7             10      115              0              0        0  35.3   \n",
              "8              2      197             70             45      543  30.5   \n",
              "9              8      125             96              0        0   0.0   \n",
              "10             4      110             92              0        0  37.6   \n",
              "11            10      168             74              0        0  38.0   \n",
              "12            10      139             80              0        0  27.1   \n",
              "13             1      189             60             23      846  30.1   \n",
              "14             5      166             72             19      175  25.8   \n",
              "15             7      100              0              0        0  30.0   \n",
              "16             0      118             84             47      230  45.8   \n",
              "17             7      107             74              0        0  29.6   \n",
              "18             1      103             30             38       83  43.3   \n",
              "19             1      115             70             30       96  34.6   \n",
              "20             3      126             88             41      235  39.3   \n",
              "21             8       99             84              0        0  35.4   \n",
              "22             7      196             90              0        0  39.8   \n",
              "23             9      119             80             35        0  29.0   \n",
              "24            11      143             94             33      146  36.6   \n",
              "25            10      125             70             26      115  31.1   \n",
              "26             7      147             76              0        0  39.4   \n",
              "27             1       97             66             15      140  23.2   \n",
              "28            13      145             82             19      110  22.2   \n",
              "29             5      117             92              0        0  34.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "738            2       99             60             17      160  36.6   \n",
              "739            1      102             74              0        0  39.5   \n",
              "740           11      120             80             37      150  42.3   \n",
              "741            3      102             44             20       94  30.8   \n",
              "742            1      109             58             18      116  28.5   \n",
              "743            9      140             94              0        0  32.7   \n",
              "744           13      153             88             37      140  40.6   \n",
              "745           12      100             84             33      105  30.0   \n",
              "746            1      147             94             41        0  49.3   \n",
              "747            1       81             74             41       57  46.3   \n",
              "748            3      187             70             22      200  36.4   \n",
              "749            6      162             62              0        0  24.3   \n",
              "750            4      136             70              0        0  31.2   \n",
              "751            1      121             78             39       74  39.0   \n",
              "752            3      108             62             24        0  26.0   \n",
              "753            0      181             88             44      510  43.3   \n",
              "754            8      154             78             32        0  32.4   \n",
              "755            1      128             88             39      110  36.5   \n",
              "756            7      137             90             41        0  32.0   \n",
              "757            0      123             72              0        0  36.3   \n",
              "758            1      106             76              0        0  37.5   \n",
              "759            6      190             92              0        0  35.5   \n",
              "760            2       88             58             26       16  28.4   \n",
              "761            9      170             74             31        0  44.0   \n",
              "762            9       89             62              0        0  22.5   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "5                       0.201   30        0  \n",
              "6                       0.248   26        1  \n",
              "7                       0.134   29        0  \n",
              "8                       0.158   53        1  \n",
              "9                       0.232   54        1  \n",
              "10                      0.191   30        0  \n",
              "11                      0.537   34        1  \n",
              "12                      1.441   57        0  \n",
              "13                      0.398   59        1  \n",
              "14                      0.587   51        1  \n",
              "15                      0.484   32        1  \n",
              "16                      0.551   31        1  \n",
              "17                      0.254   31        1  \n",
              "18                      0.183   33        0  \n",
              "19                      0.529   32        1  \n",
              "20                      0.704   27        0  \n",
              "21                      0.388   50        0  \n",
              "22                      0.451   41        1  \n",
              "23                      0.263   29        1  \n",
              "24                      0.254   51        1  \n",
              "25                      0.205   41        1  \n",
              "26                      0.257   43        1  \n",
              "27                      0.487   22        0  \n",
              "28                      0.245   57        0  \n",
              "29                      0.337   38        0  \n",
              "..                        ...  ...      ...  \n",
              "738                     0.453   21        0  \n",
              "739                     0.293   42        1  \n",
              "740                     0.785   48        1  \n",
              "741                     0.400   26        0  \n",
              "742                     0.219   22        0  \n",
              "743                     0.734   45        1  \n",
              "744                     1.174   39        0  \n",
              "745                     0.488   46        0  \n",
              "746                     0.358   27        1  \n",
              "747                     1.096   32        0  \n",
              "748                     0.408   36        1  \n",
              "749                     0.178   50        1  \n",
              "750                     1.182   22        1  \n",
              "751                     0.261   28        0  \n",
              "752                     0.223   25        0  \n",
              "753                     0.222   26        1  \n",
              "754                     0.443   45        1  \n",
              "755                     1.057   37        1  \n",
              "756                     0.391   39        0  \n",
              "757                     0.258   52        1  \n",
              "758                     0.197   26        0  \n",
              "759                     0.278   66        1  \n",
              "760                     0.766   22        0  \n",
              "761                     0.403   43        1  \n",
              "762                     0.142   33        0  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}